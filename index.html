<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Matthew Landers</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Matthew Landers</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="industry-experience.html">Experience</a></div>
<div class="menu-item"><a href="static/Matthew_Landers_CV.pdf" target="blank">CV</a></div>
<div class="menu-category">Notes</div>
<div class="menu-item"><a href="about.html"><i>About&nbsp;these&nbsp;notes</i></a></div>
<div class="menu-item"><a href="glossary.html">Glossary</a></div>
<div class="menu-item"><a href="pseudocode.html">Pseudocode</a></div>
<div class="menu-item"><a href="about-rl.html">About&nbsp;RL</a></div>
<div class="menu-item"><a href="mdp.html">MDPs</a></div>
<div class="menu-item"><a href="value-functions-and-policies.html">Value&nbsp;Func.&nbsp;&amp;&nbsp;Policies</a></div>
<div class="menu-item"><a href="dynamic-programming-for-mdps.html">DP&nbsp;for&nbsp;MDPs</a></div>
<div class="menu-item"><a href="policy-and-value-iteration-proofs.html">DP&nbsp;for&nbsp;MDPs&nbsp;Proofs</a></div>
<div class="menu-item"><a href="model-free-prediction.html">Model-Free&nbsp;Prediction</a></div>
<div class="menu-item"><a href="prediction-with-function-approximation.html">Prediction&nbsp;with&nbsp;Approx.</a></div>
<div class="menu-item"><a href="model-free-control.html">Model-Free&nbsp;Control</a></div>
<div class="menu-item"><a href="on-policy-control-with-function-approximation.html">On-Policy&nbsp;Control<br /> with&nbsp;Approximation</a></div>
<div class="menu-item"><a href="off-policy-control-with-function-approximation.html">Off-Policy&nbsp;Control<br /> with&nbsp;Approximation</a></div>
<div class="menu-item"><a href="importance-sampling.html">Importance&nbsp;Sampling</a></div>
<div class="menu-item"><a href="learnability-of-rl-objectives.html">Learnability&nbsp;of<br /> RL&nbsp;Objectives</a></div>
<div class="menu-item"><a href="the-deadly-triad.html">The&nbsp;Deadly&nbsp;Triad</a></div>
<div class="menu-item"><a href="deep-q-learning.html">Deep&nbsp;Q-Learning</a></div>
<div class="menu-item"><a href="policy-gradients.html">Policy&nbsp;Gradients</a></div>
<div class="menu-item"><a href="actor-critic.html">Actor-Critic&nbsp;Framework</a></div>
<div class="menu-item"><a href="ddpg.html">DPG&nbsp;&amp;&nbsp;DDPG</a></div>
<div class="menu-item"><a href="reparameterization-trick.html">Reparameterization&nbsp;Trick</a></div>
<div class="menu-item"><a href="sac.html">Soft&nbsp;Actor-Critic</a></div>
<div class="menu-item"><a href="grpo.html">Group&nbsp;Relative&nbsp;Policy<br /> Optimization</a></div>
<div class="menu-item"><a href="transformer.html">Transformer</a></div>
<div class="menu-item"><a href="trpo.html">TRPO</a></div>
<div class="menu-item"><a href="conjugate-gradient-method.html">Conjugate&nbsp;Gradient&nbsp;Method</a></div>
<div class="menu-item"><a href="ppo.html">PPO</a></div>
<div class="menu-item"><a href="double-q-learning.html">Double&nbsp;Q-Learning</a></div>
<div class="menu-item"><a href="td3.html">TD3</a></div>
<div class="menu-item"><a href="nn-verification.html">NN&nbsp;Verification</a></div>
<div class="menu-item"><a href="drl-verification.html">DRL&nbsp;Verification</a></div>
<div class="menu-item"><a href="alphazero.html">AlphaZero&nbsp;(chess)</a></div>
<div class="menu-item"><a href="bayes-theorem-for-probability-distributions.html">Bayes&rsquo;&nbsp;for&nbsp;Distributions</a></div>
<div class="menu-item"><a href="backpropagation.html">Backpropagation</a></div>
<div class="menu-item"><a href="off-policy-evaluation.html">Off-Policy&nbsp;Evaluation</a></div>
<div class="menu-item"><a href="constrained-mdps.html">Constrained&nbsp;MDPs</a></div>
<div class="menu-item"><a href="cpo.html">Constrained&nbsp;Policy&nbsp;<br />Optimization</a></div>
<div class="menu-item"><a href="pid-lagrangian.html">PID&nbsp;Lagrangian</a></div>
<div class="menu-item"><a href="successor-features.html">Successor&nbsp;Features</a></div>
<div class="menu-item"><a href="policy-distillation.html">Policy&nbsp;Distillation</a></div>
<div class="menu-item"><a href="kl-divergence.html">KL&nbsp;Divergence</a></div>
<div class="menu-item"><a href="implicit-q-learning.html">Implicit&nbsp;Q-Learning</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Matthew Landers</h1>
</div>
<table class="imgtable" id="bio-table"><tr><td>
<img src="static/images/Matt_Landers.jpg" alt="image of Matt Landers" />&nbsp;</td>
<td align="left"><p>Computer science PhD student in the Human-Artificial Intelligence Lab at the University of Virginia
</p>
<p><a href="static/Matthew_Landers_CV.pdf" target="blank">CV</a> · <a href="https://scholar.google.com/citations?user=yiWlY9IAAAAJ&hl=en" target="blank">Google Scholar</a> · <a href="https://www.linkedin.com/in/mattmlanders/" target="blank">LinkedIn</a>
</p>
<p>qwp4pk [at] virginia [dot] edu
</p>
</td></tr></table>
<p>I am a computer science PhD student at the University of Virginia studying under Afsaneh Doryab and Tom Hartvigsen. Previously, I earned my master's degree from Johns Hopkins University where I was advised by Suchi Saria. I have founded two startups.
</p>
<p>My research focuses on trustworthy deep reinforcement learning approaches designed for real-world systems. I am especially interested in methods that can account for environmental constraints, human feedback, and other types of domain knowledge.
</p>
<h3>Papers</h3>
<dl>
<dt>Improving and Accelerating Offline RL in Large Discrete Action Spaces with Structured Policy Initialization, <i>Under Review</i> (2025)</dt>
<dd><p><b>Matthew Landers</b>, Taylor W. Killian, Thomas Hartvigsen, Afsaneh Doryab
</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/pdf/2505.12109" target=&ldquo;blank&rdquo;>SAINT: Attention-Based Policies for Discrete Combinatorial Action Spaces</a>, <i>Under Review</i> (2025)</dt>
<dd><p><b>Matthew Landers</b>, Taylor W. Killian, Thomas Hartvigsen, Afsaneh Doryab
</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/pdf/2410.21151" target=&ldquo;blank&rdquo;>BraVE: Offline Reinforcement Learning for Discrete Combinatorial Action Spaces</a>, NeurIPS (2025)</dt>
<dd><p><b>Matthew Landers</b>, Taylor W. Killian, Hugo Barnes, Thomas Hartvigsen, Afsaneh Doryab
</p></dd>
</dl>
<dl>
<dt><a href="https://ieeexplore.ieee.org/document/11228810" target=&ldquo;blank&rdquo;>Parameter Transfer for Single-Task Reinforcement Learning</a>, International Joint Conference on Neural Networks (2025)</dt>
<dd><p><b>Matthew Landers</b> and Afsaneh Doryab
</p></dd>
</dl>
<dl>
<dt><a href="https://dl.acm.org/doi/10.1145/3596444" target=&ldquo;blank&rdquo;>Deep Reinforcement Learning Verification: A Survey</a>, ACM Computing Surveys (2023)</dt>
<dd><p><b>Matthew Landers</b> and Afsaneh Doryab
</p></dd>
</dl>
<dl>
<dt><a href="https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocac065/6586579" target=&ldquo;blank&rdquo;>A bias evaluation checklist for predictive models and its pilot application for 30-day hospital readmission models</a>,
Journal of the American Medical Informatics Association (2022)</dt>
<dd><p>Echo Wang*, <b>Matthew Landers*</b>, Roy Adams*, Adarsh Subbaswamy, Hadi Kharrazi, Darrell Gaskin, and Suchi Saria
</p></dd>
</dl>
<dl>
<dt><a href="https://www.karger.com/Article/Abstract/517885" target=&ldquo;blank&rdquo;>Digital Endpoints: Definition, Benefits, and Current Barriers in Accelerating Development and Adoption</a>,
Digital Biomarkers (2021)</dt>
<dd><p><b>Matthew Landers</b>, Ray Dorsey, and Suchi Saria
</p></dd>
</dl>
<dl>
<dt><a href="https://content.iospress.com/articles/journal-of-parkinsons-disease/jpd212545" target=&ldquo;blank&rdquo;>Will Artificial Intelligence Replace the Movement Disorders Specialist for Diagnosing and Managing Parkinson’s Disease?</a>,
Journal of Parkinson’s Disease (2021)</dt>
<dd><p><b>Matthew Landers</b>, Suchi Saria, and Alberto Espay
</p></dd>
</dl>
<dl>
<dt><a href="https://www.mdpi.com/1424-8220/21/22/7510" target=&ldquo;blank&rdquo;>Prediction of Hospital Readmission from Longitudinal Mobile Data Streams</a>,
Sensors (2021)</dt>
<dd><p>Chen Qian, Patraporn Leelaprachakul, <b>Matthew Landers</b>, Carissa Low, Anind K . Dey, and Afsaneh Doryab
</p></dd>
</dl>
<p>* indicates equal contribution
</p>
<div id="footer">
<div id="footer-text">
Page generated 2025-12-04 15:37:28 PST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
<!-- GoatCounter Analytics -->
<script data-goatcounter="https://mattlanders.goatcounter.com/count"
        async src="//gc.zgo.at/count.js">
</script>
</head>
<body>
